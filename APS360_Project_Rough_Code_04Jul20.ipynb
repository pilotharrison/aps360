{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "APS360 Project - Rough Code - 04Jul20.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EijjhFVG0U-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "outputId": "2e32df75-44eb-40c3-bc06-158b5194dda2"
      },
      "source": [
        "!pip install torchaudio==0.4.0 torch==1.4.0 comet-ml==3.0.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/bc/3ebc127162d27bed33dc914606f10117d106680baae7ce83603ea09985fd/torchaudio-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 2.8MB/s \n",
            "\u001b[?25hCollecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 19kB/s \n",
            "\u001b[?25hCollecting comet-ml==3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/c6/fac88f43f2aa61a09fee4ffb769c73fe93fe7de75764246e70967d31da09/comet_ml-3.0.2-py3-none-any.whl (170kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 48.9MB/s \n",
            "\u001b[?25hCollecting netifaces>=0.10.7\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/9b/c4c7eb09189548d45939a3d3a6b3d53979c67d124459b27a094c365c347f/netifaces-0.10.9-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting everett[ini]>=1.0.1; python_version >= \"3.0\"\n",
            "  Downloading https://files.pythonhosted.org/packages/12/34/de70a3d913411e40ce84966f085b5da0c6df741e28c86721114dd290aaa0/everett-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (2.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (1.12.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (2.23.0)\n",
            "Collecting websocket-client>=0.55.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 46.3MB/s \n",
            "\u001b[?25hCollecting comet-git-pure>=0.19.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/7a/483413046e48908986a0f9a1d8a917e1da46ae58e6ba16b2ac71b3adf8d7/comet_git_pure-0.19.16-py3-none-any.whl (409kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 41.6MB/s \n",
            "\u001b[?25hCollecting wurlitzer>=1.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/24/5e/f3bd8443bfdf96d2f5d10097d301076a9eb55637b7864e52d2d1a4d8c72a/wurlitzer-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet-ml==3.0.2) (7.352.0)\n",
            "Collecting configobj; extra == \"ini\"\n",
            "  Downloading https://files.pythonhosted.org/packages/64/61/079eb60459c44929e684fa7d9e2fdca403f67d64dd9dbac27296be2e0fab/configobj-5.0.6.tar.gz\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml==3.0.2) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml==3.0.2) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet-ml==3.0.2) (1.24.3)\n",
            "Building wheels for collected packages: configobj\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configobj: filename=configobj-5.0.6-cp36-none-any.whl size=34546 sha256=63b27be6d525c239d82c0c2833114be696e98ce2882ca133a51df36099498b68\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/e4/16/4981ca97c2d65106b49861e0b35e2660695be7219a2d351ee0\n",
            "Successfully built configobj\n",
            "\u001b[31mERROR: torchvision 0.6.1+cu101 has requirement torch==1.5.1, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchaudio, netifaces, configobj, everett, websocket-client, comet-git-pure, wurlitzer, comet-ml\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "Successfully installed comet-git-pure-0.19.16 comet-ml-3.0.2 configobj-5.0.6 everett-1.0.2 netifaces-0.10.9 torch-1.4.0 torchaudio-0.4.0 websocket-client-0.57.0 wurlitzer-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo8dgVEvHNP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from comet_ml import Experiment\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "\n",
        "def avg_wer(wer_scores, combined_ref_len):\n",
        "  return float(sum(wer_Scores)) / float(combined_ref_len)\n",
        "\n",
        "def __levenshtein_distance(ref, hyp):\n",
        "  # measures difference between two sequences\n",
        "  soln = len(ref)\n",
        "  resp = len(hyp)\n",
        "\n",
        "  # if sequences are the same/null\n",
        "  if ref == hyp:\n",
        "    return 0\n",
        "  if soln == 0:\n",
        "    return resp\n",
        "  if resp ==0:\n",
        "    return soln\n",
        "\n",
        "  # distance calculation\n",
        "  if soln < resp:\n",
        "    ref, hyp = hyp, ref\n",
        "    soln, resp = resp, soln\n",
        "\n",
        "  #starting with 0 space\n",
        "  distance = np.zeros((2, resp+1), dtype=np.int32)\n",
        "\n",
        "  #distance matrix initialization\n",
        "  for j in range(0, resp+1):\n",
        "    distance[0][j] = j\n",
        "\n",
        "  # calculate levenshtein distance\n",
        "  for i in range(1, soln + 1):\n",
        "    prev_row = (i - 1) % 2\n",
        "    cur_row = i % 2\n",
        "    distance[cur_row][0] = i\n",
        "    for j in range(1, soln + 1):\n",
        "      if ref[i-1] == hyp[j-1]:\n",
        "        distance[cur_row][j] = distance[prev_row]\n",
        "      else:\n",
        "        s_num = distance[prev_row][j-1] + 1 #words substituted\n",
        "        i_num = distance[cur_row][j-1] + 1 #words inserted\n",
        "        d_num = distance[prev_row][j] + 1 #words deleted\n",
        "        distance[cur_row][j] = min(s_num, i_num, d_num)\n",
        "\n",
        "  return distance[soln % 2][resp]\n",
        "\n",
        "def word_errors(ref, hyp, delimiter=' '):\n",
        "  # returns word level levenshtein distances of hypothesis from reference in a list format; not case sensitive\n",
        "\n",
        "  reference = ref.lower()\n",
        "  hypothesis = hyp.lower()\n",
        "\n",
        "  ref_words = reference.split(delimiter)\n",
        "  hyp_words = hypothesis.split(delimiter)\n",
        "\n",
        "  distance = _levenshtein_distance(ref_words, hyp_words)\n",
        "\n",
        "  return float(distance), len(ref_words)\n",
        "\n",
        "def char_errors(ref, hyp):\n",
        "# returns word level levenshtein distances of hypothesis from reference in a list format; not case sensitive\n",
        "\n",
        "  reference = ref.lower()\n",
        "  hypothesis = hyp.lower()\n",
        "\n",
        "  join_char = ' '\n",
        "\n",
        "  reference = join_char.join(filter(None, reference.split(' ')))\n",
        "  hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
        "\n",
        "  distance = _levenshtein_distance(reference, hypothesis)\n",
        "\n",
        "  return float(distance, len(reference))\n",
        "\n",
        "def wer(ref, hyp, delimieter = ' '):\n",
        "# computes word error rate -> number of words substituted, deleted, or inserted divided by number of words in reference\n",
        "  distance, ref_len = word_errors(ref, hyp, delimiter)\n",
        "\n",
        "  wer = float(distance) / ref_len\n",
        "\n",
        "  return wer\n",
        "\n",
        "def cer(ref, hyp):\n",
        "# computes character error rate -> number of characters substituted, deleted, or inserted divided by number of characters in reference  \n",
        "  distance, ref_len = char_errors(ref, hyp)\n",
        "\n",
        "  cer = float(distance) / ref_len\n",
        "\n",
        "  return cer \n",
        "\n",
        "class txtTransform:\n",
        "  def _init_(self):\n",
        "    # mapping characters to integers for converting text to integer sequence, and vice versa\n",
        "    char_map_str = \"\"\"\n",
        "     ' 0\n",
        "        <SPACE> 1\n",
        "        a 2\n",
        "        b 3\n",
        "        c 4\n",
        "        d 5\n",
        "        e 6\n",
        "        f 7\n",
        "        g 8\n",
        "        h 9\n",
        "        i 10\n",
        "        j 11\n",
        "        k 12\n",
        "        l 13\n",
        "        m 14\n",
        "        n 15\n",
        "        o 16\n",
        "        p 17\n",
        "        q 18\n",
        "        r 19\n",
        "        s 20\n",
        "        t 21\n",
        "        u 22\n",
        "        v 23\n",
        "        w 24\n",
        "        x 25\n",
        "        y 26\n",
        "        z 27\n",
        "        \"\"\"\n",
        "    self.char_map = {}\n",
        "    self.index_map = {}\n",
        "    for line in char_map_str.strip().split('\\n'):\n",
        "      ch, index = line.split()         \n",
        "      self.char_map[ch] = int(index)\n",
        "      self.index_map[int(index)] = ch\n",
        "      self.index_map[1] = ' '\n",
        "\n",
        "  def text_to_int(self, text):\n",
        "    # convert text to integer sequence\n",
        "    int_sequence = []\n",
        "    for char in text:\n",
        "      if char == ' ':\n",
        "        ch = self.char_map['<SPACE>']\n",
        "      else:\n",
        "        ch = self.char_map[c]\n",
        "      int_sequence.append(ch)\n",
        "    \n",
        "    return int_sequence\n",
        "\n",
        "  def int_to_text(self, labels):\n",
        "    # convert integer sequence to text\n",
        "    text = []\n",
        "    for i in labels:\n",
        "      text.append(self.index_map[i])\n",
        "    \n",
        "    return ''.join(text).replace('<SPACE>', ' ')\n",
        "\n",
        "# create spectogram from audio signal\n",
        "train_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100))\n",
        "\n",
        "valid_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30), #data augmentation\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)) #data augmentation\n",
        "\n",
        "text_transform = txtTransform()\n",
        "\n",
        "def data_processing(data, data_type = \"train\"):\n",
        "  spectrograms = []\n",
        "  labels = []\n",
        "  input_lengths = []\n",
        "  label_lengths = []\n",
        "  for (mp3, _, utterance, _, _, _) in data:\n",
        "    if data_type == 'train':\n",
        "      spec = train_audio_transforms(mp3).squeeze(0).transpose(0,1)\n",
        "    elif data_Type == 'valid':\n",
        "      spec = valid_audio_transforms(mp3).squeeze(0).transpose(0, 1)\n",
        "    spectograms.append(spec)\n",
        "    label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "    labels.append(label)\n",
        "    input_lengths.append(spec.shape[0]//2)\n",
        "    label_lengths.append(len(label))\n",
        "\n",
        "def Decoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
        "  arg_maxes = torch.argmax(output, dim=2)\n",
        "  decoded = []\n",
        "  targets = []     \n",
        "  for i, args in enumerate(arg_maxes):\n",
        "    decoded = []\n",
        "    targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "    for j, index in enumerate(args):\n",
        "      if index != blank_label:\n",
        "        if collapse_repeated and j != 0 and index == args[j-1]:\n",
        "          continue\n",
        "        decode.append(index.item())\n",
        "      decoded.append(text_transform.int_to_text(decode))\n",
        "    return decoded, targets\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJB99NB6gqKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class speechRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(speechRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)\n",
        "    self.fc = nn.Linear(hidden_size, num_classes)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "    c0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "    # Forward propagate the LSTM\n",
        "    out, _ = self.rnn(x, (h0, c0))\n",
        "    # Pass the output of the last time step to the classifier\n",
        "    out = self.fc(out[:, -1, :])\n",
        "    \n",
        "    return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdtbca9VnEDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IterMeter(object):\n",
        "  #tracking number of iterations\n",
        "  def __init__(self):\n",
        "    self.val = 0\n",
        "\n",
        "  def step(self):\n",
        "    self.val += 1\n",
        "\n",
        "  def get(self):\n",
        "    return self.val  \n",
        "    \n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X6TuTGOchaf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "outputId": "01f4ba31-9ca1-4846-a55a-c73d5b9791fa"
      },
      "source": [
        "comet_api_key = \"FYqH757a4Za03rbnYfB9ic1MF\" # add your api key here\n",
        "project_name = \"aps360-speech-recognition\"\n",
        "experiment_name = \"aps360roughcode-colab\"\n",
        "\n",
        "if comet_api_key:\n",
        "  experiment = Experiment(api_key=comet_api_key, project_name=project_name, parse_args=False)\n",
        "  experiment.set_name(experiment_name)\n",
        "  experiment.display()\n",
        "else:\n",
        "  experiment = Experiment(api_key='dummy_key', disabled=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: old comet version (3.0.2) detected. current: 3.1.12 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/abox3/aps360-speech-recognition/b8bacc1da44948d68c6375f58056c18b\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"800px\"\n",
              "            src=\"https://www.comet.ml/abox3/aps360-speech-recognition/b8bacc1da44948d68c6375f58056c18b\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7fbca37e4d30>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}