{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"APS360 Project - Rough Code.ipynb","provenance":[],"authorship_tag":"ABX9TyMYnsUNZwM1yfPM7Bs/e1Ld"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"G-tJKg6CwanV","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torchtext\n","import fasttext.util\n","\n","# file location (make sure to use your file location)\n","file_dir = '/content/drive/Shared with me/APS360 Project/Preprocessed Data/'\n","\n","def get_data():\n","    return csv.reader(open(file_dir + \"training.1600000.processed.noemoticon.csv\",\"rt\", encoding=\"latin-1\"))\n","\n","\n","#pre-trained embedding - GloVe\n","glove = torchtext.vocab.GloVe(name=\"6B\",dim=50) #OR load embedding layer separately\n","glove_emb = nn.Embedding.from_pretrained(glove.vectors)\n","\n","##pre-trained embedding - FastText\n","fasttext.util.download_model('en', if_exists='ignore')  # English\n","ft = fasttext.load_model('cc.en.300.bin')\n","#\n","fastxt = torchtext.vocab.FastText(language='en')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Rk27KlUvQll","colab_type":"code","colab":{}},"source":["def get_tweet_words(glove_vector):\n","    train, valid, test = [], [], []\n","    for i, line in enumerate(get_data()):\n","        if i % 29 == 0:\n","            tweet = line[-1]\n","            idxs = [glove_vector.stoi[w]        # lookup the index of word\n","                    for w in split_tweet(tweet)\n","                    if w in glove_vector.stoi] # keep words that has an embedding\n","            if not idxs: # ignore tweets without any word with an embedding\n","                continue\n","            idxs = torch.tensor(idxs) # convert list to pytorch tensor\n","            label = torch.tensor(int(line[0] == \"4\")).long()\n","            if i % 5 < 3:\n","                train.append((idxs, label))\n","            elif i % 5 == 4:\n","                valid.append((idxs, label))\n","            else:\n","                test.append((idxs, label))\n","    return train, valid, test\n","\n","train, valid, test = get_tweet_words(glove)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oyGFOu6rv5BM","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","def train_network(model, train_loader, valid_loader, num_epochs=5, learning_rate=1e-5):\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","    losses, train_acc, valid_acc = [], [], []\n","    epochs = []\n","    for epoch in range(num_epochs):\n","        for tweets, labels in train_loader:\n","            optimizer.zero_grad()\n","            pred = model(tweets)\n","            loss = criterion(pred, labels)\n","            loss.backward()\n","            optimizer.step()\n","            \n","        losses.append(float(loss))     \n","        if epoch % 5 == 4:\n","            epochs.append(epoch)\n","            train_acc.append(get_accuracy(model, train_loader))\n","            valid_acc.append(get_accuracy(model, valid_loader))\n","            print(\"Epoch %d; Loss %f; Train Acc %f; Val Acc %f\" % (\n","                epoch+1, loss, train_acc[-1], valid_acc[-1]))\n","\n","    # plotting\n","    plt.title(\"Training Curve\")\n","    plt.plot(losses, label=\"Train\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.show()\n","\n","    plt.title(\"Training Curve\")\n","    plt.plot(epochs, train_acc, label=\"Train\")\n","    plt.plot(epochs, valid_acc, label=\"Validation\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.legend(loc='best')\n","    plt.show()\n","\n","def get_accuracy(model, data_loader):\n","    correct, total = 0, 0\n","    for tweets, labels in data_loader:\n","        output = model(tweets)\n","        pred = output.max(1, keepdim=True)[1]\n","        correct += pred.eq(labels.view_as(pred)).sum().item()\n","        total += labels.shape[0]\n","    return correct / total"],"execution_count":null,"outputs":[]}]}