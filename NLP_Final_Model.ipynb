{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import gc\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input the necessary directories\n",
    "\n",
    "#Excel Files containing file names and labels\n",
    "excel_root = r'G:/School/2020 Mozilla Dataset/Excel Files/'\n",
    "\n",
    "# Location of where the unzipped numpy files are located\n",
    "root = r'G:/School/2020 Mozilla Dataset/mp3_to_np'\n",
    "''' \n",
    "Note: Audio files must first be converted to spectrogram\n",
    "as a numpy array on Google Colab before running this code on\n",
    "local machine that runs Windows 10. Windows 10 cannot run\n",
    "Torchaudio, which is required to convert audio files (such\n",
    "as mp3, wav, or m4a) to spectrograms.\n",
    "'''\n",
    "\n",
    "# Location of pretrained saved models\n",
    "model_fpath = r'G:/School/2020 Mozilla Dataset/saved_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all the train, val, and test file names and labels\n",
    "\n",
    "train_excel = pd.read_excel(excel_root + 'train.xlsx', sheet_name=0)\n",
    "val_excel = pd.read_excel(excel_root + 'validation.xlsx', sheet_name=0)\n",
    "test_excel = pd.read_excel(excel_root + 'test.xlsx', sheet_name=0)\n",
    "\n",
    "# Train\n",
    "train_filenames_labels = (train_excel['path'].tolist(), train_excel['sentence'].tolist())\n",
    "\n",
    "# Validation\n",
    "val_filenames_labels = (val_excel['path'].tolist(), val_excel['sentence'].tolist())\n",
    "\n",
    "# Test\n",
    "test_filenames_labels = (test_excel['path'].tolist(), test_excel['sentence'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a silu function\n",
    "\n",
    "def silu(input):\n",
    "    '''\n",
    "    Applies the Sigmoid Linear Unit (SiLU) function element-wise:\n",
    "        SiLU(x) = x * sigmoid(x)\n",
    "    '''\n",
    "    return input * torch.sigmoid(input) # use torch.sigmoid to make sure that we created the most efficient implemetation based on builtin PyTorch functions\n",
    "\n",
    "# create a class wrapper from PyTorch nn.Module, so\n",
    "# the function now can be easily used in models\n",
    "class SiLU(nn.Module):\n",
    "    '''\n",
    "    Applies the Sigmoid Linear Unit (SiLU) function element-wise:\n",
    "        SiLU(x) = x * sigmoid(x)\n",
    "    Shape:\n",
    "        - Input: (N, *) where * means, any number of additional\n",
    "          dimensions\n",
    "        - Output: (N, *), same shape as the input\n",
    "    References:\n",
    "        -  Related paper:\n",
    "        https://arxiv.org/pdf/1606.08415.pdf\n",
    "    Examples:\n",
    "        >>> m = silu()\n",
    "        >>> input = torch.randn(2)\n",
    "        >>> output = m(input)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Init method.\n",
    "        '''\n",
    "        super().__init__() # init the base class\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        Forward pass of the function.\n",
    "        '''\n",
    "        return silu(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for pre-processing data\n",
    "\n",
    "class TextTransform:\n",
    "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
    "    def __init__(self):\n",
    "        char_map_str = \"\"\"\n",
    "        ' 0\n",
    "        <SPACE> 1\n",
    "        a 2\n",
    "        b 3\n",
    "        c 4\n",
    "        d 5\n",
    "        e 6\n",
    "        f 7\n",
    "        g 8\n",
    "        h 9\n",
    "        i 10\n",
    "        j 11\n",
    "        k 12\n",
    "        l 13\n",
    "        m 14\n",
    "        n 15\n",
    "        o 16\n",
    "        p 17\n",
    "        q 18\n",
    "        r 19\n",
    "        s 20\n",
    "        t 21\n",
    "        u 22\n",
    "        v 23\n",
    "        w 24\n",
    "        x 25\n",
    "        y 26\n",
    "        z 27\n",
    "        \"\"\"\n",
    "        self.char_map = {}\n",
    "        self.index_map = {}\n",
    "        for line in char_map_str.strip().split('\\n'):\n",
    "            ch, index = line.split()\n",
    "            self.char_map[ch] = int(index)\n",
    "            self.index_map[int(index)] = ch\n",
    "        self.index_map[1] = ' '\n",
    "\n",
    "    def text_to_int(self, text):\n",
    "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
    "        int_sequence = []\n",
    "        for c in text:\n",
    "            if c == ' ':\n",
    "                ch = self.char_map['<SPACE>']\n",
    "            else:\n",
    "                ch = self.char_map[c]\n",
    "            int_sequence.append(ch)\n",
    "        return int_sequence\n",
    "\n",
    "    def int_to_text(self, labels):\n",
    "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
    "        string = []\n",
    "        for i in labels:\n",
    "            string.append(self.index_map[i])\n",
    "        return ''.join(string).replace('<SPACE>', ' ')\n",
    "\n",
    "text_transform = TextTransform()\n",
    "\n",
    "def data_processing(data):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    for (spec, utterance) in data:\n",
    "        spectrograms.append(torch.Tensor(spec).detach())\n",
    "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
    "        labels.append(label.detach())\n",
    "        input_lengths.append(torch.Tensor(spec).detach().shape[0]//2)\n",
    "        label_lengths.append(len(label.detach()))\n",
    "\n",
    "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths\n",
    "\n",
    "def Decoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
    "    arg_maxes = torch.argmax(output, dim=2)\n",
    "    decodes = []\n",
    "    targets = []\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "      decode = []\n",
    "      targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "      for j, index in enumerate(args):\n",
    "        if index != blank_label:\n",
    "          if collapse_repeated and j != 0 and index == args[j -1]:\n",
    "            continue\n",
    "          decode.append(index.item())\n",
    "      decodes.append(text_transform.int_to_text(decode))\n",
    "    return decodes, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Data Loader that can load custom dataset\n",
    "\n",
    "def load_speech_item(file_name, label_text, path):\n",
    "    fpath = path + '/' + file_name\n",
    "\n",
    "    # Load Audio\n",
    "    spec = np.load(fpath)   \n",
    "\n",
    "    return (spec, label_text)\n",
    "\n",
    "class Data_Loader(Dataset):\n",
    "    def __init__(self, root, filenames_labels):\n",
    "        self._path = root\n",
    "        self._filenames, self._labels = filenames_labels\n",
    "\n",
    "    def __getitem__(self, n):\n",
    "        file_name = self._filenames[n] + \".npy\"\n",
    "        label_text = self._labels[n]\n",
    "        return load_speech_item(file_name, label_text, self._path)\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self._filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Model\n",
    "\n",
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "        self.silu = SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = self.silu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = self.silu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        return x # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class BidirectionalGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "\n",
    "        self.BiGRU = nn.GRU(\n",
    "            input_size=rnn_dim, hidden_size=hidden_size,\n",
    "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.silu = SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.silu(x)\n",
    "        x, _ = self.BiGRU(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SpeechRecognitionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(SpeechRecognitionModel, self).__init__()\n",
    "        n_feats = n_feats//2\n",
    "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.rescnn_layers = nn.Sequential(*[\n",
    "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
    "            for _ in range(n_cnn_layers)\n",
    "        ])\n",
    "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
    "        self.birnn_layers = nn.Sequential(*[\n",
    "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
    "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
    "            for i in range(n_rnn_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
    "            SiLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(rnn_dim, n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.rescnn_layers(x)\n",
    "        \n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        x = x.transpose(1, 2) # (batch, time, feature)\n",
    "        \n",
    "        x = self.fully_connected(x)\n",
    "        x = self.birnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation\n",
    "\n",
    "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch):\n",
    "    model.train()\n",
    "    data_len = len(train_loader.dataset)\n",
    "    losses = []\n",
    "\n",
    "    for batch_idx, _data in enumerate(train_loader):\n",
    "        spectrograms, labels, input_lengths, label_lengths = _data \n",
    "        \n",
    "        if spectrograms.shape[3] > 2600:\n",
    "            print(\"Skipped a batch because it is too large (>2600). Sequence length is\", spectrograms.shape[3])\n",
    "            continue\n",
    "\n",
    "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(spectrograms)  # (batch, time, n_class)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "        \n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "        losses.append(round(loss.detach().item(), 4))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(spectrograms), data_len,\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "        del spectrograms, labels\n",
    "        gc.collect()  \n",
    "    \n",
    "    return losses\n",
    "\n",
    "def test(model, device, test_loader, criterion, epoch):\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    losses = []\n",
    "    data_len = len(test_loader.dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, _data in enumerate(test_loader):\n",
    "            spectrograms, labels, input_lengths, label_lengths = _data \n",
    "            \n",
    "            if spectrograms.shape[3] > 2600:\n",
    "                print(\"Skipped a batch because it is too large (>2600). Sequence length is\", spectrograms.shape[3])\n",
    "                continue                \n",
    "\n",
    "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "            output = model(spectrograms)  # (batch, time, n_class)\n",
    "            output = F.log_softmax(output, dim=2)\n",
    "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "            test_loss += loss.item() / len(test_loader)\n",
    "\n",
    "            decoded_preds, decoded_targets = Decoder(output.transpose(0, 1), labels, label_lengths)\n",
    "            \n",
    "            if i % 100 == 0 or i == data_len:\n",
    "                print(decoded_preds, decoded_targets)\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            del spectrograms, labels\n",
    "            gc.collect()   \n",
    "\n",
    "    print(f'Test set: Average loss: {test_loss}.\\n')\n",
    "    \n",
    "    return round(test_loss, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model, optimizer, scheduler, hparams, train_loader, \n",
    "        test_loader, learning_rate=5e-4, batch_size=20, epochs=10):\n",
    "    \n",
    "    losses_train, losses_val = [], []\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CTCLoss(blank=28).to(device)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        losses_train.append(train(model, device, train_loader, criterion, optimizer, scheduler, epoch))\n",
    "        losses_val.append(test(model, device, test_loader, criterion, epoch))\n",
    "        \n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict()\n",
    "        }\n",
    "        \n",
    "        lr = hparams['learning_rate']\n",
    "        model_name = f'Final_Model_epoch_{epoch}_lr_{lr}.pt'\n",
    "        torch.save(state, hparams['model_fpath'] + model_name)\n",
    "        \n",
    "    return losses_train, losses_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters\n",
    "\n",
    "learning_rate = 5e-4\n",
    "batch_size = 4\n",
    "epochs = 10\n",
    "hparams = {\n",
    "    \"n_cnn_layers\": 4,\n",
    "    \"n_rnn_layers\": 4,\n",
    "    \"rnn_dim\": 1024,\n",
    "    \"n_class\": 29,\n",
    "    \"n_feats\": 128,\n",
    "    \"stride\":2,\n",
    "    \"dropout\": 0.1,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": epochs,\n",
    "    \"model_fpath\": model_fpath\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pretrained Model\n",
    "load_pretrained = False\n",
    "model_name = f'Final_Model_epoch_3.pt'\n",
    "\n",
    "# Setup CUDA and load data\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "train_dataset = Data_Loader(root, train_filenames_labels)\n",
    "test_dataset = Data_Loader(root, val_filenames_labels)\n",
    "\n",
    "kwargs = {'num_workers': 0, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                            batch_size=hparams['batch_size'],\n",
    "                            shuffle=True,\n",
    "                            collate_fn=lambda x: data_processing(x),\n",
    "                            **kwargs)\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                            batch_size=hparams['batch_size'],\n",
    "                            shuffle=False,\n",
    "                            collate_fn=lambda x: data_processing(x),\n",
    "                            **kwargs)\n",
    "\n",
    "if load_pretrained:\n",
    "    filepath = model_fpath + model_name\n",
    "    state = torch.load(filepath)\n",
    "\n",
    "model = SpeechRecognitionModel(\n",
    "    hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
    "    hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
    "    ).to(device)\n",
    "if load_pretrained:\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
    "if load_pretrained:\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
    "                                        steps_per_epoch=int(len(train_loader)),\n",
    "                                        epochs=hparams['epochs'],\n",
    "                                        anneal_strategy='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "losses_train, losses_val = main(model, optimizer, scheduler, hparams, train_loader, \n",
    "                                test_loader, learning_rate, batch_size, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([list(i) for i in zip(*losses_train)])\n",
    "writer = pd.ExcelWriter('Final_Model_reducedLR_losses_train.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer,sheet_name='losses_train',index=False)\n",
    "writer.save() \n",
    "'''\n",
    "Saves where this juypter notebook is saved. To check where the excel file is located,\n",
    "run the code below %pwd.\n",
    "'''\n",
    "\n",
    "\n",
    "df = pd.DataFrame(losses_val)\n",
    "writer = pd.ExcelWriter('Final_Model_reducedLR_losses_val.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer,sheet_name='losses_val',index=False)\n",
    "writer.save()\n",
    "'''\n",
    "Saves where this juypter notebook is saved. To check where the excel file is located,\n",
    "run the code below %pwd.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
