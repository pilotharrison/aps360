{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "APS360 Project - Rough Code - 04Jul20.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EijjhFVG0U-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torchaudio==0.4.0 torch==1.4.0 comet-ml==3.0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo8dgVEvHNP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from comet_ml import Experiment\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "def avg_wer(wer_scores, combined_ref_len):\n",
        "  return float(sum(wer_Scores)) / float(combined_ref_len)\n",
        "\n",
        "def __levenshtein_distance(ref, hyp):\n",
        "  # measures difference between two sequences\n",
        "  soln = len(ref)\n",
        "  resp = len(hyp)\n",
        "\n",
        "  # if sequences are the same/null\n",
        "  if ref == hyp:\n",
        "    return 0\n",
        "  if soln == 0:\n",
        "    return resp\n",
        "  if resp ==0:\n",
        "    return soln\n",
        "\n",
        "  # distance calculation\n",
        "  if soln < resp:\n",
        "    ref, hyp = hyp, ref\n",
        "    soln, resp = resp, soln\n",
        "\n",
        "  #starting with 0 space\n",
        "  distance = np.zeros((2, resp+1), dtype=np.int32)\n",
        "\n",
        "  #distance matrix initialization\n",
        "  for j in range(0, resp+1):\n",
        "    distance[0][j] = j\n",
        "\n",
        "  # calculate levenshtein distance\n",
        "  for i in range(1, soln + 1):\n",
        "    prev_row = (i - 1) % 2\n",
        "    cur_row = i % 2\n",
        "    distance[cur_row][0] = i\n",
        "    for j in range(1, soln + 1):\n",
        "      if ref[i-1] == hyp[j-1]:\n",
        "        distance[cur_row][j] = distance[prev_row]\n",
        "      else:\n",
        "        s_num = distance[prev_row][j-1] + 1 #words substituted\n",
        "        i_num = distance[cur_row][j-1] + 1 #words inserted\n",
        "        d_num = distance[prev_row][j] + 1 #words deleted\n",
        "        distance[cur_row][j] = min(s_num, i_num, d_num)\n",
        "\n",
        "  return distance[soln % 2][resp]\n",
        "\n",
        "def word_errors(ref, hyp, delimiter=' '):\n",
        "  # returns word level levenshtein distances of hypothesis from reference in a list format; not case sensitive\n",
        "\n",
        "  reference = ref.lower()\n",
        "  hypothesis = hyp.lower()\n",
        "\n",
        "  ref_words = reference.split(delimiter)\n",
        "  hyp_words = hypothesis.split(delimiter)\n",
        "\n",
        "  distance = _levenshtein_distance(ref_words, hyp_words)\n",
        "\n",
        "  return float(distance), len(ref_words)\n",
        "\n",
        "def char_errors(ref, hyp):\n",
        "# returns word level levenshtein distances of hypothesis from reference in a list format; not case sensitive\n",
        "\n",
        "  reference = ref.lower()\n",
        "  hypothesis = hyp.lower()\n",
        "\n",
        "  join_char = ' '\n",
        "\n",
        "  reference = join_char.join(filter(None, reference.split(' ')))\n",
        "  hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
        "\n",
        "  distance = _levenshtein_distance(reference, hypothesis)\n",
        "\n",
        "  return float(distance, len(reference))\n",
        "\n",
        "def wer(ref, hyp, delimieter = ' '):\n",
        "# computes word error rate -> number of words substituted, deleted, or inserted divided by number of words in reference\n",
        "  distance, ref_len = word_errors(ref, hyp, delimiter)\n",
        "\n",
        "  wer = float(distance) / ref_len\n",
        "\n",
        "  return wer\n",
        "\n",
        "def cer(ref, hyp):\n",
        "# computes character error rate -> number of characters substituted, deleted, or inserted divided by number of characters in reference  \n",
        "  distance, ref_len = char_errors(ref, hyp)\n",
        "\n",
        "  cer = float(distance) / ref_len\n",
        "\n",
        "  return cer \n",
        "\n",
        "class txtTransform:\n",
        "  def _init_(self):\n",
        "    # mapping characters to integers for converting text to integer sequence, and vice versa\n",
        "    char_map_str = \"\"\"\n",
        "     ' 0\n",
        "        <SPACE> 1\n",
        "        a 2\n",
        "        b 3\n",
        "        c 4\n",
        "        d 5\n",
        "        e 6\n",
        "        f 7\n",
        "        g 8\n",
        "        h 9\n",
        "        i 10\n",
        "        j 11\n",
        "        k 12\n",
        "        l 13\n",
        "        m 14\n",
        "        n 15\n",
        "        o 16\n",
        "        p 17\n",
        "        q 18\n",
        "        r 19\n",
        "        s 20\n",
        "        t 21\n",
        "        u 22\n",
        "        v 23\n",
        "        w 24\n",
        "        x 25\n",
        "        y 26\n",
        "        z 27\n",
        "        \"\"\"\n",
        "    self.char_map = {}\n",
        "    self.index_map = {}\n",
        "    for line in char_map_str.strip().split('\\n'):\n",
        "      ch, index = line.split()         \n",
        "      self.char_map[ch] = int(index)\n",
        "      self.index_map[int(index)] = ch\n",
        "      self.index_map[1] = ' '\n",
        "\n",
        "  def text_to_int(self, text):\n",
        "    # convert text to integer sequence\n",
        "    int_sequence = []\n",
        "    for char in text:\n",
        "      if char == ' ':\n",
        "        ch = self.char_map['<SPACE>']\n",
        "      else:\n",
        "        ch = self.char_map[c]\n",
        "      int_sequence.append(ch)\n",
        "    \n",
        "    return int_sequence\n",
        "\n",
        "  def int_to_text(self, labels):\n",
        "    # convert integer sequence to text\n",
        "    text = []\n",
        "    for i in labels:\n",
        "      text.append(self.index_map[i])\n",
        "    \n",
        "    return ''.join(text).replace('<SPACE>', ' ')\n",
        "\n",
        "# create spectrogram from audio signal\n",
        "train_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100))\n",
        "\n",
        "val_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30), #data augmentation\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)) #data augmentation\n",
        "\n",
        "test_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30), #data augmentation\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)) #data augmentation\n",
        "\n",
        "\n",
        "text_transform = txtTransform()\n",
        "\n",
        "def data_processing(data, data_type = \"train\"):\n",
        "  spectrograms = []\n",
        "  labels = []\n",
        "  input_lengths = []\n",
        "  label_lengths = []\n",
        "  for (mp3, _, utterance, _, _, _) in data:\n",
        "    if data_type == 'train':\n",
        "      spec = train_audio_transforms(mp3).squeeze(0).transpose(0,1)\n",
        "    elif data_Type == 'valid':\n",
        "      spec = valid_audio_transforms(mp3).squeeze(0).transpose(0, 1)\n",
        "    spectrograms.append(spec)\n",
        "    label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "    labels.append(label)\n",
        "    input_lengths.append(spec.shape[0]//2)\n",
        "    label_lengths.append(len(label))\n",
        "\n",
        "def Decoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
        "  arg_maxes = torch.argmax(output, dim=2)\n",
        "  decodes = []\n",
        "  targets = []     \n",
        "  for i, args in enumerate(arg_maxes):\n",
        "    decodes = []\n",
        "    targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "    for j, index in enumerate(args):\n",
        "      if index != blank_label:\n",
        "        if collapse_repeated and j != 0 and index == args[j-1]:\n",
        "          continue\n",
        "        decode.append(index.item())\n",
        "      decodes.append(text_transform.int_to_text(decode))\n",
        "    return decodes, targets\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdrP5rwWTD0r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9026c291-8298-42b2-a2bc-b486a44d6e18"
      },
      "source": [
        "cwd = os.getcwd()\n",
        "files = os.listdir(cwd)  # Get all the files in that directory\n",
        "print(\"Files in %r: %s\" % (cwd, files))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files in '/content': ['.config', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t01vgebD_8-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdFsLypfUess",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples = load_workbook (r'/content/drive/My Drive/APS360 - AI Fundamentals/Project/Validated Samples.xlsx')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVIFzRqrcwGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find the number of pre-processed data in train, val, and test files\n",
        "fpath_train = r'/content/drive/My Drive/APS360 - AI Fundamentals/Project/train/'\n",
        "fpath_val = r'/content/drive/My Drive/APS360 - AI Fundamentals/Project/val/'\n",
        "fpath_test =r'/content/drive/My Drive/APS360 - AI Fundamentals/Project/test/'\n",
        "\n",
        "num_train = len(os.listdir(fpath_train))\n",
        "num_val = len(os.listdir(fpath_val))\n",
        "num_test = len(os.listdir(fpath_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM9Mm1u3kEDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Obtain original row index used in spectrogram code\n",
        "np.random.seed(50)\n",
        "lastrow = samples['Validated_Samples'].max_row\n",
        "range_array = np.array(range(2,lastrow + 1))\n",
        "np.random.shuffle(range_array)\n",
        "\n",
        "range_train = range_array[:num_train]\n",
        "range_val = range_array[num_train:num_train + num_val]\n",
        "range_test = range_array[num_train + num_val:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJB99NB6gqKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class speechRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(speechRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)\n",
        "    self.fc = nn.Linear(hidden_size, num_classes)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "    c0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "    # Forward propagate the LSTM\n",
        "    out, _ = self.rnn(x, (h0, c0))\n",
        "    # Pass the output of the last time step to the classifier\n",
        "    out = self.fc(out[:, -1, :])\n",
        "    \n",
        "    return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdtbca9VnEDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IterMeter(object):\n",
        "  #tracking number of iterations\n",
        "  def __init__(self):\n",
        "    self.val = 0\n",
        "\n",
        "  def step(self):\n",
        "    self.val += 1\n",
        "\n",
        "  def get(self):\n",
        "    return self.val  \n",
        "\n",
        " def train(model, device, train_loader, criterion, optimizer, epoch, iter_meter, experiment):\n",
        "   model.train()\n",
        "   data_len = len(train_loader.dataset)\n",
        "   with experiment.train():\n",
        "     for batch_idx, data in enumerate(train_loader):\n",
        "       spectrograms, labels, input_lengths, label_lengths = data\n",
        "       spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "       optimizer.zero_grad()\n",
        "\n",
        "       output = model(spectrograms)\n",
        "       output = F.log_softmax(output, dim=2)\n",
        "       output = output.transpose(0,1)\n",
        "\n",
        "       loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "       loss.backward()\n",
        "\n",
        "       experiment.log_metric('loss', loss.item(), step+iter_meter.get())\n",
        "       experiment.log_metric('learning_rate', step=iter_meter.get())\n",
        "\n",
        "       optimizer.step()\n",
        "       iter_meter.step()\n",
        "\n",
        "  def val(model, device, test_loader, criterion, epoch, iter_meter, experiment):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_cer, val_wer = [], []\n",
        "    with experiment.val()\n",
        "      with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader):\n",
        "          spectrograms, labels, input_lengths, label_lengths = data\n",
        "          spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "          output = model(spectrograms)\n",
        "          output = F.log_softmax(output, dim=2)\n",
        "          output = output.transpose(0,1)\n",
        "\n",
        "          loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "          val_loss += loss.item() / len(val_loader)\n",
        "\n",
        "          decoded_preds, decoded_targets = Decoder(output.transpose(0,1), labels, label_lengths)\n",
        "          for j in range(len(Decoded_preds)):\n",
        "            val_cer.append(cer(Decoded_targets[j], decoded_preds[j]))\n",
        "            val_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
        "  avg_cer = sum(val_cer)/len(val_cer)\n",
        "  avg_wer = sum(val_wer)/len(val_wer)\n",
        "  experiment.log_metric('val_loss', val_loss, step=iter_meter.get())\n",
        "  experiment.log_metric('cer', avg_cer, step=iter_meter.get())\n",
        "  experiment.log_metric('wer', avg_wer, step=iter_meter.get())\n",
        "\n",
        "  print('Val set: average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(val_loss, avg_cer, avg_wer))\n",
        "\n",
        "  def main(learning_Rate = xxxxx, batch_size = xxx, epochs = xxx, t)\n",
        "    \n",
        "    hparams = {\n",
        "        \"n_cnn_layers\": 3,\n",
        "        \"n_rnn_layers\": 5,\n",
        "        \"rnn_dim\": 512,\n",
        "        \"n_class\": 29,\n",
        "        \"n_feats\": 128,\n",
        "        \"stride\":2,\n",
        "        \"dropout\": 0.1,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs\n",
        "    }\n",
        "\n",
        "    experiment.log_parameters(hparams)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    torch.manual_seed(7)\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    \n",
        "    if not os.path.isdir(\"./data\"):\n",
        "        os.makedirs(\"./data\")\n",
        "\n",
        "    model = SpeechRecognitionModel(\n",
        "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
        "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
        "        ).to(device)\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
        "    criterion = nn.CTCLoss(blank=28).to(device)\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
        "                                            steps_per_epoch=int(len(train_loader)),\n",
        "                                            epochs=hparams['epochs'],\n",
        "                                            anneal_strategy='linear')\n",
        "\n",
        "    iter_meter = IterMeter()\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, experiment)\n",
        "        test(model, device, test_loader, criterion, epoch, iter_meter, experiment)    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X6TuTGOchaf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "outputId": "01f4ba31-9ca1-4846-a55a-c73d5b9791fa"
      },
      "source": [
        "comet_api_key = \"FYqH757a4Za03rbnYfB9ic1MF\" # add your api key here\n",
        "project_name = \"aps360-speech-recognition\"\n",
        "experiment_name = \"aps360roughcode-colab\"\n",
        "\n",
        "if comet_api_key:\n",
        "  experiment = Experiment(api_key=comet_api_key, project_name=project_name, parse_args=False)\n",
        "  experiment.set_name(experiment_name)\n",
        "  experiment.display()\n",
        "else:\n",
        "  experiment = Experiment(api_key='dummy_key', disabled=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: old comet version (3.0.2) detected. current: 3.1.12 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/abox3/aps360-speech-recognition/b8bacc1da44948d68c6375f58056c18b\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"800px\"\n",
              "            src=\"https://www.comet.ml/abox3/aps360-speech-recognition/b8bacc1da44948d68c6375f58056c18b\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7fbca37e4d30>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}