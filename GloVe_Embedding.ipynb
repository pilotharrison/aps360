{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GloVe Embedding.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Joi0fM9MW9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Wikipedia 2014 and Gigaword 5\n",
        "glove = torchtext.vocab.GloVe(name=\"6B\", dim= 100)   # embedding size = 100\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_oRTPHSNOab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#setup Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgNFpppWQjPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load csv\n",
        "def get_data():\n",
        "  return csv.reader(open('/content/drive/My Drive/APS360 - AI Fundamentals/Project/Validated Samples.csv',\"rt\", encoding = \"latin-1\"))\n",
        "\n",
        "for i, line in enumerate(get_data()):\n",
        "    if line[1] != 'path':\n",
        "        print(line[1], line[2])\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-Q3TXOYUor_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_phrase(phrase):\n",
        "  # add spaces before and after punctuations to split text into words\n",
        "  phrase = phrase.replace(\".\",\" . \") \\\n",
        "                  .replace(\",\",\" , \") \\\n",
        "                  .replace(\";\",\" ; \") \\\n",
        "                  .replace(\"\\\"\",\" \\\" \") \\\n",
        "                  .replace(\"!\",\" ! \")\n",
        "  return phrase.lower().split()\n",
        "\n",
        "split_phrase(\"test, this! out\")    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaBcCyqGWLB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#number of words in each phrase that have GloVe embeddings\n",
        "for i, line in enumerate(get_data()):\n",
        "    if i > 10: #first 10 items\n",
        "        break\n",
        "    print(sum(int(w in glove.stoi) for w in split_phrase(line[2])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgzjAVGdYheT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_phrase_vectors(glove_vector):\n",
        "  train, validation, test = [], [], []\n",
        "  for i, line in enumerate(get_data()):\n",
        "    phrase = line[2]\n",
        "    if i % 59 == 0:\n",
        "      phrase = phrase[2]\n",
        "      idxs = [glove_vector.stoi[w]\n",
        "              for w in split_phrase(phrase)\n",
        "              if w in glove_vector.stoi]\n",
        "      if not idxs:\n",
        "        continue\n",
        "      idxs = torch.tensor(idxs)\n",
        "      label = torch.tensor(int(line[1] != 'path')).long() #label - path label\n",
        "      if i % 5 < 3:#60%\n",
        "        train.append((idxs, label))\n",
        "      elif i % 5 == 4: #20%\n",
        "        validation.append((idxs, label))\n",
        "      else: #20%\n",
        "        test.append((idxs, label))\n",
        "  return train, validation, test\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4giIOl1aVZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, validation, test = get_phrase_vectors(glove)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=128, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=128, shuffle=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wYHglaRdiYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "phrase, label = train[0]\n",
        "print(label, phrase)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWgTAvEhYDKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_emb = nn.Embedding.from_pretrained(glove.vectors)\n",
        "\n",
        "phrase_emb = glove_emb(phrase)\n",
        "phrase_emb.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P1ECA-cY_RV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PhraseRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(PhraseRNN, self).__init__()\n",
        "        self.emb = nn.Embedding.from_pretrained(glove.vectors)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size = 100, hidden_size = 100, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Look up the embedding\n",
        "        x = self.emb(x)\n",
        "        # Set an initial hidden state\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        # Forward propagate the RNN\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        # Pass the output of the last time step to the classifier\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "model = PhraseRNN(100, 100, 1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8599AoBVbfkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(10):\n",
        "  phrase, label = train[i]\n",
        "  print(phrase.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUeiKGlyb1Kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pad sequences with zero inputs\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "phrase_padded = pad_sequence([phrase for phrase, label in train[:10]],\n",
        "                            batch_first=True)\n",
        "print(phrase_padded.shape)\n",
        "print(phrase_padded[0:2])\n",
        "\n",
        "out = model(phrase_padded)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}